@InProceedings{EssanoahArthur2024,
  author    = {Essanoah Arthur, Ewura Abena and Aabangbio Wulnye, Fortunatus and Nana Gookyi, Dennis Agyemanh and Obour Agyekum, Kwame Opuni-Boachie and Danquah, Paul and Gyaang, Raymond},
  booktitle = {2024 Conference on Information Communications Technology and Society (ICTAS)},
  title     = {Edge Impulse vs TensorFlow: A Comparative Analysis of TinyML Platforms for Maize Leaf Disease Identification},
  year      = {2024},
  pages     = {1-6},
  doi       = {10.1109/ICTAS59620.2024.10507119},
  keywords  = {Training;Microcontrollers;Image edge detection;Scalability;Data models;Reliability;Stakeholders;TensorFlow;Edge Impulse;machine learning;Maize leaf disease identification;disease identification},
}

@article{Oladokun2025,
  author       = {Martins Oladokun},
  title        = {Latency and Throughput Tradeoffs in Real‑Time IoT Data Analytics},
  journal      = {arXiv preprint arXiv:2505.XXXX},
  year         = {2025},
  month        = may,
  note         = {Discusses desafios de latência em setores como saúde, transporte e manufatura em aplicações de IoT em tempo real},
}


@Article{Xavier2022,
  author    = {Tiago C. S. Xavier and Flavia C. Delicato and Paulo F. Pires and Claudio L. Amorim and Wei Li and Albert Zomaya},
  title     = {Managing Heterogeneous and Time-Sensitive {IoT} Applications through Collaborative and Energy-Aware Resource Allocation},
  journal   = {ACM Transactions on Internet of Things},
  volume    = {3},
  number    = {2},
  pages     = {10:1--10:28},
  month     = may,
  year      = {2022},
  doi       = {10.1145/3488248},
  abstract  = {In the Internet of Things (IoT) environment, the computing resources available in the cloud are often unable to meet the latency constraints of time critical applications due to the large distance between the cloud and data sources (IoT devices).},
}


@Article{Shamim2022,
  author   = {Shamim, Mohammed Zubair M.},
  journal  = {IEEE Embedded Systems Letters},
  title    = {Hardware Deployable Edge-AI Solution for Prescreening of Oral Tongue Lesions Using TinyML on Embedded Devices},
  year     = {2022},
  number   = {4},
  pages    = {183-186},
  volume   = {14},
  doi      = {10.1109/LES.2022.3160281},
  keywords = {Lesions;Tongue;Cancer;Computational modeling;Image edge detection;Training;Performance evaluation;Artificial intelligence (AI);embedded edge devices;oral cavity cancer (OCC);tiny machine learning (TinyML);tongue lesions},
}

@Article{Yap2024,
  author   = {Yap, Yan Siang and Ahmad, Mohd Ridzuan},
  journal  = {IEEE Sensors Letters},
  title    = {Modified Overcomplete Autoencoder for Anomaly Detection Based on TinyML},
  year     = {2024},
  number   = {10},
  pages    = {1-4},
  volume   = {8},
  doi      = {10.1109/LSENS.2024.3463977},
  keywords = {Training;Decoding;Microcontrollers;Tiny machine learning;Accuracy;Computer architecture;Autoencoders;Mechanical systems;Sensors;Mechanical sensors;anomaly detection;autoencoder (AE);embedded system;tiny machine learning (TinyML)},
}

@Article{Mellit2025,
  author   = {Mellit, A. and Blasuttigh, N. and Pastore, S. and Zennaro, M. and Pavan, A. Massi},
  journal  = {IEEE Transactions on Industry Applications},
  title    = {TinyML for Fault Diagnosis of Photovoltaic Modules Using Edge Impulse Platform and IR Thermography Images},
  year     = {2025},
  pages    = {1-12},
  doi      = {10.1109/TIA.2025.3556792},
  keywords = {Image edge detection;Fault diagnosis;Accuracy;Tiny machine learning;Fault detection;Classification algorithms;Real-time systems;Infrared imaging;Imputation;Data models;Photovoltaic;fault diagnosis;TinyML;edge impulse;edge device},
}

@InProceedings{Buteau2024,
  author    = {Buteau, Étienne and Gagné, Gabriel and Bonilla, William and Boukadoum, Mounir and Fortier, Paul and Gosselin, Benoit},
  booktitle = {2024 46th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)},
  title     = {TinyML for Real-Time Embedded HD-EMG Hand Gesture Recognition with On-Device Fine-Tuning},
  year      = {2024},
  pages     = {1-6},
  doi       = {10.1109/EMBC53108.2024.10781755},
  keywords  = {Performance evaluation;Cloud computing;Wireless sensor networks;Quantization (signal);Accuracy;Tiny machine learning;Gesture recognition;Real-time systems;Artificial intelligence;Prosthetics;Artificial intelligence (AI);AI accelerator;biomedical;data quantization;electromyography (EMG);embedded device;hand gesture recognition (HGR);HD-EMG;tinyML},
}

@InProceedings{Flores2023,
  author    = {Flores, Thommas and Silva, Marianne and Azevedo, Mariana and Medeiros, Thais and Medeiros, Morsinaldo and Silva, Ivanovitch and Dias Santos, Max Mauro and Costa, Daniel G.},
  booktitle = {2023 IEEE International Workshop on Metrology for Automotive (MetroAutomotive)},
  title     = {TinyML for Safe Driving: The Use of Embedded Machine Learning for Detecting Driver Distraction},
  year      = {2023},
  pages     = {62-66},
  doi       = {10.1109/MetroAutomotive57488.2023.10219132},
  keywords  = {Performance evaluation;Road accidents;Image edge detection;Computational modeling;Random access memory;Machine learning;Behavioral sciences;Embedded machine learning;Computer vision;TinyML;Driver distraction;Arduino Portenta H7},
}

@InProceedings{Wulnye2024,
  author    = {Wulnye, Fortunatus Aabangbio and Essanoah Arthur, Ewura Abena and Nana Gookyi, Dennis Agyemanh and Kwaku Pobi Asiedu, Derek and Wilson, Michael and Agyemang, Justice Owusu},
  booktitle = {2024 Conference on Information Communications Technology and Society (ICTAS)},
  title     = {TinyML Implementation on Microcontrollers: The Case of Maize Leaf Disease Identification},
  year      = {2024},
  pages     = {180-185},
  doi       = {10.1109/ICTAS59620.2024.10507115},
  keywords  = {Training;Microcontrollers;Crops;Random access memory;Data augmentation;Convolutional neural networks;Object recognition;Convolutional Neural Network;maize leaf disease;optimization;microcontroller unit},
}

@InProceedings{Samanta2024,
  author    = {Samanta, Riya and Saha, Bidyut and Ghosh, Soumya K.},
  booktitle = {2024 IEEE Space, Aerospace and Defence Conference (SPACE)},
  title     = {TinyML-On-The-Fly: Real-Time Low-Power and Low-Cost MCU-Embedded On-Device Computer Vision for Aerial Image Classification},
  year      = {2024},
  pages     = {194-198},
  doi       = {10.1109/SPACE63117.2024.10667906},
  keywords  = {Computer vision;Accuracy;Tiny machine learning;Surveillance;Computational modeling;Urban planning;Autonomous aerial vehicles;Aerial Image Classification;Computer Vision;MobileNet;TinyML;On-device Inference;UAV},
}

@Article{boinapalli2020digital,
  author  = {Boinapalli, Narasimha Rao},
  journal = {NEXG AI Review of America},
  title   = {Digital Transformation in US Industries: AI as a Catalyst for Sustainable Growth},
  year    = {2020},
  number  = {1},
  pages   = {70--84},
  volume  = {1},
}

@Article{Sinha2024,
  author    = {Satyajit Sinha},
  title     = {State of IoT 2024: Number of connected IoT devices growing 13\% to 18.8 billion globally},
  year      = {2024},
  timestamp = {22/05/2025},
  url       = {https://iot-analytics.com/number-connected-iot-devices/},
}

@INPROCEEDINGS{dataCNN,
	author={Luo, Chao and Li, Xiaojie and Wang, Lutao and He, Jia and Li, Denggao and Zhou, Jiliu},
	booktitle={2018 5th International Conference on Systems and Informatics (ICSAI)}, 
	title={How Does the Data set Affect CNN-based Image Classification Performance?}, 
	year={2018},
	volume={},
	number={},
	pages={361-366},
	keywords={Training;Training data;Feature extraction;Convolution;Kernel;5G mobile communication;Neural networks;Multi-classification;CNN;ResNet},
	doi={10.1109/ICSAI.2018.8599448}}


@InProceedings{iot2018,
	author={Routh, Koustav and Pal, Tannistha},
	booktitle={2018 3rd International Conference On Internet of Things: Smart Innovation and Usages (IoT-SIU)}, 
	title={A survey on technological, business and societal aspects of Internet of Things by Q3, 2017}, 
	year={2018},
	volume={},
	number={},
	pages={1-4},
	keywords={Internet of Things;Industries;Security;Computational modeling;Companies;IoT;challenges;technical;business;society;relations},
	doi={10.1109/IoT-SIU.2018.8519898}}

@InProceedings{iotSaude,
	author    = {Shwetha, D. and Swetha},
	booktitle = {Proceedings of the 2024 International Conference on Advances in Modern Age Technologies for Health and Engineering Science (AMATHE)},
	title     = {IoT's Impact on Personal Devices and Health: Wearable Technology},
	year      = {2024},
	pages     = {1--8},
	doi       = {10.1109/AMATHE61652.2024.10582194},
	keywords  = {Data privacy;Data security;Ecosystems;Medical services;Streaming media;Real-time systems;Internet of Things;Internet of Things (IoT);Health Wearable Technology;Personal Devices;Real-time Health Monitoring;Data Privacy and Security;Predictive Health Management;IoT Ecosystem in Healthcare;Smart Health Wearables}
}

@InProceedings{impactOfData,
	author="Linjordet, Trond
	and Balog, Krisztian",
	editor="Azzopardi, Leif
	and Stein, Benno
	and Fuhr, Norbert
	and Mayr, Philipp
	and Hauff, Claudia
	and Hiemstra, Djoerd",
	title="Impact of Training Dataset Size on Neural Answer Selection Models",
	booktitle="Advances in Information Retrieval",
	year="2019",
	publisher="Springer International Publishing",
	address="Cham",
	pages="828--835",
	abstract="It is held as a truism that deep neural networks require large datasets to train effective models. However, large datasets, especially with high-quality labels, can be expensive to obtain. This study sets out to investigate (i) how large a dataset must be to train well-performing models, and (ii) what impact can be shown from fractional changes to the dataset size. A practical method to investigate these questions is to train a collection of deep neural answer selection models using fractional subsets of varying sizes of an initial dataset. We observe that dataset size has a conspicuous lack of effect on the training of some of these models, bringing the underlying algorithms into question.",
	isbn="978-3-030-15712-8"
}

@misc{kaggle,
  author       = {Kaggle},
  title        = {Kaggle: Your Machine Learning and Data Science Community},
  year         = {2023},
  url          = {https://www.kaggle.com},
  note         = {Accessed: 2024-11-02}
}

@misc{uTensor,
  title = {uTensor: Biblioteca de inferência para TinyML},
  author = {{Colaboradores do uTensor}},
  year = {2025},
  note = {Disponível em: \url{https://github.com/uTensor/uTensor}},
}

@article{Ahmed2022,
  title={An Investigation on Disparity Responds of Machine Learning Algorithms to Data Normalization Method},
  author={Ahmed, Haval A. and Muhammad Ali, Peshawa J. and Faeq, Abdulbasit K. and Abdullah, Saman M.},
  journal={ARO - The Scientific Journal of Koya University},
  volume={10},
  number={2},
  pages={29--37},
  year={2022},
  month={Sep},
  doi={10.14500/aro.10970},
  url={https://aro.koyauniversity.org/index.php/aro/article/view/970},
  abstract={Data normalization can be useful in eliminating the effect of inconsistent ranges in some machine learning (ML) techniques and in speeding up the optimization process in others. Many studies apply different methods of data normalization with an aim to reduce or eliminate the impact of data variance on the accuracy rate of ML-based models. However, the significance of this impact aligning with the mathematical concept of the ML algorithms still needs more investigation and tests. To identify that, this work proposes an investigation methodology involving three different ML algorithms, which are support vector machine (SVM), artificial neural network (ANN), and Euclidean-based K-nearest neighbor (E-KNN). Throughout this work, five different datasets have been utilized, and each has been taken from different application fields with different statistical properties. Although there are many data normalization methods available, this work focuses on the min-max method, because it actively eliminates the effect of inconsistent ranges of the datasets. Moreover, other factors that are challenging the process of min-max normalization, such as including or excluding outliers or the least significant feature, have also been considered in this work. The finding of this work shows that each ML technique responds differently to the min-max normalization. The performance of SVM models has been improved, while no significant improvement happened to the performance of ANN models. It is been concluded that the performance of E-KNN models may improve or degrade with the min-max normalization, and it depends on the statistical properties of the dataset.}
}


@Article{Whang2023,
  author   = {Whang, Steven Euijong and Roh, Yuji and Song, Hwanjun and Lee, Jae-Gil},
  journal  = {The VLDB Journal},
  title    = {Data collection and quality challenges in deep learning: a data-centric AI perspective},
  year     = {2023},
  issn     = {0949-877X},
  month    = {Jul},
  number   = {4},
  pages    = {791-813},
  volume   = {32},
  abstract = {Data-centric AI is at the center of a fundamental shift in software engineering where machine learning becomes the new software, powered by big data and computing infrastructure. Here, software engineering needs to be re-thought where data become a first-class citizen on par with code. One striking observation is that a significant portion of the machine learning process is spent on data preparation. Without good data, even the best machine learning algorithms cannot perform well. As a result, data-centric AI practices are now becoming mainstream. Unfortunately, many datasets in the real world are small, dirty, biased, and even poisoned. In this survey, we study the research landscape for data collection and data quality primarily for deep learning applications. Data collection is important because there is lesser need for feature engineering for recent deep learning approaches, but instead more need for large amounts of data. For data quality, we study data validation, cleaning, and integration techniques. Even if the data cannot be fully cleaned, we can still cope with imperfect data during model training using robust model training techniques. In addition, while bias and fairness have been less studied in traditional data management research, these issues become essential topics in modern machine learning applications. We thus study fairness measures and unfairness mitigation techniques that can be applied before, during, or after model training. We believe that the data management community is well poised to solve these problems.},
  day      = {01},
  doi      = {10.1007/s00778-022-00775-9},
  url      = {https://doi.org/10.1007/s00778-022-00775-9},
}



@Article{specificDomain,
AUTHOR = {Miller, Tymoteusz and Durlik, Irmina and Łobodzińska, Adrianna and Dorobczyński, Lech and Jasionowski, Robert},
TITLE = {AI in Context: Harnessing Domain Knowledge for Smarter Machine Learning},
JOURNAL = {Applied Sciences},
VOLUME = {14},
YEAR = {2024},
NUMBER = {24},
ARTICLE-NUMBER = {11612},
URL = {https://www.mdpi.com/2076-3417/14/24/11612},
ISSN = {2076-3417},
ABSTRACT = {This article delves into the critical integration of domain knowledge into AI/ML systems across various industries, highlighting its importance in developing ethically responsible, effective, and contextually relevant solutions. Through detailed case studies from the healthcare and manufacturing sectors, we explore the challenges, strategies, and successes of this integration. We discuss the evolving role of domain experts and the emerging tools and technologies that facilitate the incorporation of human expertise into AI/ML models. The article forecasts future trends, predicting a more seamless and strategic collaboration between AI/ML and domain expertise. It emphasizes the necessity of this synergy for fostering innovation, ensuring ethical practices, and aligning technological advancements with human values and real-world complexities.},
DOI = {10.3390/app142411612}
}

@Article{datasetSize,
AUTHOR = {Althnian, Alhanoof and AlSaeed, Duaa and Al-Baity, Heyam and Samha, Amani and Dris, Alanoud Bin and Alzakari, Najla and Abou Elwafa, Afnan and Kurdi, Heba},
TITLE = {Impact of Dataset Size on Classification Performance: An Empirical Evaluation in the Medical Domain},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {796},
URL = {https://www.mdpi.com/2076-3417/11/2/796},
ISSN = {2076-3417},
ABSTRACT = {Dataset size is considered a major concern in the medical domain, where lack of data is a common occurrence. This study aims to investigate the impact of dataset size on the overall performance of supervised classification models. We examined the performance of six widely-used models in the medical field, including support vector machine (SVM), neural networks (NN), C4.5 decision tree (DT), random forest (RF), adaboost (AB), and naïve Bayes (NB) on eighteen small medical UCI datasets. We further implemented three dataset size reduction scenarios on two large datasets and analyze the performance of the models when trained on each resulting dataset with respect to accuracy, precision, recall, f-score, specificity, and area under the ROC curve (AUC). Our results indicated that the overall performance of classifiers depend on how much a dataset represents the original distribution rather than its size. Moreover, we found that the most robust model for limited medical data is AB and NB, followed by SVM, and then RF and NN, while the least robust model is DT. Furthermore, an interesting observation is that a robust machine learning model to limited dataset does not necessary imply that it provides the best performance compared to other models.},
DOI = {10.3390/app11020796}
}

@InProceedings{iotAgricultura,
	author={Kjellby, Rolf A. and Cenkeramaddi, Linga R. and Frøytlog, Anders and Lozano, Baltasar B. and Soumya, J. and Bhange, Meghana},
	booktitle={2019 IEEE 5th World Forum on Internet of Things (WF-IoT)}, 
	title={Long-range \& Self-powered IoT Devices for Agriculture \& Aquaponics Based on Multi-hop Topology}, 
	year={2019},
	volume={},
	number={},
	pages={545-549},
	keywords={Logic gates;Protocols;Agriculture;Energy harvesting;Energy consumption;Internet of Things;Topology;Wireless Sensor Networks;IoT;Wireless Embedded Systems;Energy Harvesting;Self-Powered IoT;Multi-Hop Topology;Agriculture;Aquaponics},
	doi={10.1109/WF-IoT.2019.8767196}}

@INPROCEEDINGS{iotIndustria,
  author={Demir, Erkan and Korkmaz, Hayriye},
  booktitle={2023 IEEE International Workshop on Metrology for Industry 4.0 \& IoT (MetroInd4.0\&IoT)}, 
  title={A Novel Monitoring Dashboard And Hardware Implementation Simplifying The Remote Access In Industry}, 
  year={2023},
  volume={},
  number={},
  pages={399-403},
  keywords={Industries;Industrial facilities;Inverters;Delays;Problem-solving;Personnel;Internet of Things;Industrial IoT;Machine-Cloud-Human Interaction;Remote Monitoring and Control;Frequency Inverters;Smart Machines;Smart Factories},
  doi={10.1109/MetroInd4.0IoT57462.2023.10180193}}

@InProceedings{latencia,
	author={Zen, Kartinah and Mohanan, Saju and Tarmizi, Seleviawati and Annuar, Noralifah and Sama, Najm Us},
	booktitle={2022 Applied Informatics International Conference (AiIC)}, 
	title={Latency Analysis of Cloud Infrastructure for Time-Critical IoT Use Cases}, 
	year={2022},
	volume={},
	number={},
	pages={111-116},
	keywords={Cloud computing;Program processors;Machine learning algorithms;Web services;Data processing;Manipulators;Real-time systems;Latency;IoT;Edge Computing;Cloud Computing;RTT},
	doi={10.1109/AiIC54368.2022.9914601}}

@InProceedings{edge,
  author    = {Saraswathi, S.},
  booktitle = {2025 International Conference on Emerging Smart Computing and Informatics (ESCI)},
  title     = {Optimizing Latency and Energy Efficiency in Edge Computing with Reinforcement Learning and TinyML},
  year      = {2025},
  pages     = {1-8},
  doi       = {10.1109/ESCI63694.2025.10987923},
  keywords  = {Adaptation models;Energy consumption;Accuracy;Federated learning;Computational modeling;Tiny machine learning;Medical services;Reinforcement learning;Throughput;Real-time systems;AI-Driven Adaptive Edge Computing Framework;TinyML;Federated Learning;latency;throughput;and energy consumption},
}

@misc{harvard_dataverse,
	author       = {Harvard Dataverse},
	title        = {Harvard Dataverse: An Online Repository for Research Data},
	year         = {2025},
	url          = {https://dataverse.harvard.edu},
	note         = {Acessado em: 4 jun. 2025}
}

@misc{edge_impulse,
	author       = {Edge Impulse, Inc.},
	title        = {Edge Impulse: The Leading Edge AI Development Platform},
	year         = {2025},
	url          = {https://www.edgeimpulse.com},
	note         = {Acessado em: 4 jun. 2025}
}

@misc{litert2024,
	author       = {Google AI Edge},
	title        = {LiteRT: High-Performance On-Device AI Runtime (formerly TensorFlow Lite)},
	year         = {2024},
	url          = {https://ai.google.dev/edge/litert},
	note         = {Acessado em: 4 jun. 2025}
}

@article{10million,
title = {Open access image repositories: high-quality data to enable machine learning research},
journal = {Clinical Radiology},
volume = {75},
number = {1},
pages = {7-12},
year = {2020},
issn = {0009-9260},
doi = {https://doi.org/10.1016/j.crad.2019.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S0009926019301692},
author = {F. Prior and J. Almeida and P. Kathiravelu and T. Kurc and K. Smith and T.J. Fitzgerald and J. Saltz},
abstract = {Originally motivated by the need for research reproducibility and data reuse, large-scale, open access information repositories have become key resources for training and testing of advanced machine learning applications in biomedical and clinical research. To be of value, such repositories must provide large, high-quality data sets, where quality is defined as minimising variance due to data collection protocols and data misrepresentations. Curation is the key to quality. We have constructed a large public access image repository, The Cancer Imaging Archive, dedicated to the promotion of open science to advance the global effort to diagnose and treat cancer. Drawing on this experience and our experience in applying machine learning techniques to the analysis of radiology and pathology image data, we will review the requirements placed on such information repositories by state-of-the-art machine learning applications and how these requirements can be met.}
}

@ARTICLE{Guemes-Pena2018-ma,
  title    = "Emerging topics in mining software repositories",
  author   = "G{\"u}emes-Pe{\~n}a, Diego and L{\'o}pez-Nozal, Carlos and
              Marticorena-S{\'a}nchez, Ra{\'u}l and Maudes-Raedo, Jes{\'u}s",
  abstract = "A software process is a set of related activities that culminates
              in the production of a software package: specification, design,
              implementation, testing, evolution into new versions, and
              maintenance. There are also other supporting activities such as
              configuration and change management, quality assurance, project
              management, evaluation of user experience, etc. Software
              repositories are infrastructures to support all these activities.
              They can be composed with several systems that include code
              change management, bug tracking, code review, build system,
              release binaries, wikis, forums, etc. This position paper on
              mining software repositories presents a review and a discussion
              of research in this field over the past decade. We also identify
              applied machine learning strategies, current working topics, and
              future challenges for the improvement of company decision-making
              systems. Machine learning is defined as the process of
              discovering patterns in data. It can be applied to software
              repositories, since every change is recorded as data. Companies
              can then use these patterns as the basis for their
              decision-making systems and for knowledge discovery.",
  journal  = "Progress in Artificial Intelligence",
  volume   =  7,
  number   =  3,
  pages    = "237--247",
  month    =  sep,
  year     =  2018
}

@InProceedings{tinyModels,
  author    = {Han, Hui and Siebert, Julien},
  booktitle = {2022 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)},
  title     = {TinyML: A Systematic Review and Synthesis of Existing Research},
  year      = {2022},
  pages     = {269-274},
  doi       = {10.1109/ICAIIC54071.2022.9722636},
  keywords  = {Privacy;Systematics;Machine learning algorithms;Software algorithms;Machine learning;Hardware;Software;TinyML;Systematic review;Data synthesis;MCUs;TensorFlow Lite;Neural networks},
}

@InProceedings{comparaAlg,
  author    = {Poojary, Ramaprasad and Pai, Akul},
  booktitle = {2019 International Conference on Electrical and Computing Technologies and Applications (ICECTA)},
  title     = {Comparative Study of Model Optimization Techniques in Fine-Tuned CNN Models},
  year      = {2019},
  pages     = {1-4},
  doi       = {10.1109/ICECTA48151.2019.8959681},
  keywords  = {Deep learning;Convolutional Neural Network;Fine-Tuning;Model-Optimizer},
}

@Article{Wang2022,
  author   = {Wang, Qi and Ma, Yue and Zhao, Kun and Tian, Yingjie},
  journal  = {Annals of Data Science},
  title    = {A Comprehensive Survey of Loss Functions in Machine Learning},
  year     = {2022},
  issn     = {2198-5812},
  month    = {Apr},
  number   = {2},
  pages    = {187-212},
  volume   = {9},
  abstract = {As one of the important research topics in machine learning, loss function plays an important role in the construction of machine learning algorithms and the improvement of their performance, which has been concerned and explored by many researchers. But it still has a big gap to summarize, analyze and compare the classical loss functions. Therefore, this paper summarizes and analyzes 31 classical loss functions in machine learning. Specifically, we describe the loss functions from the aspects of traditional machine learning and deep learning respectively. The former is divided into classification problem, regression problem and unsupervised learning according to the task type. The latter is subdivided according to the application scenario, and here we mainly select object detection and face recognition to introduces their loss functions. In each task or application, in addition to analyzing each loss function from formula, meaning, image and algorithm, the loss functions under the same task or application are also summarized and compared to deepen the understanding and provide help for the selection and improvement of loss function.},
  day      = {01},
  doi      = {10.1007/s40745-020-00253-5},
  url      = {https://doi.org/10.1007/s40745-020-00253-5},
}

@Article{Kallimani2024,
  author   = {Kallimani, Rakhee and Pai, Krishna and Raghuwanshi, Prasoon and Iyer, Sridhar and L{\'o}pez, Onel L. A.},
  journal  = {Multimedia Tools and Applications},
  title    = {TinyML: Tools, applications, challenges, and future research directions},
  year     = {2024},
  issn     = {1573-7721},
  month    = {Mar},
  number   = {10},
  pages    = {29015-29045},
  volume   = {83},
  abstract = {In recent years, Artificial Intelligence (AI) and Machine learning (ML) have gained significant interest from both, industry and academia. Notably, conventional ML techniques require enormous amounts of power to meet the desired accuracy, which has limited their use mainly to high-capability devices such as network nodes. However, with many advancements in technologies such as the Internet of Things (IoT) and edge computing, it is desirable to incorporate ML techniques into resource-constrained embedded devices for distributed and ubiquitous intelligence. This has motivated the emergence of the TinyML paradigm which is an embedded ML technique that enables ML applications on multiple cheap, resource- and power-constrained devices. However, during this transition towards appropriate implementation of the TinyML technology, multiple challenges such as processing capacity optimisation, improved reliability, and maintenance of learning models' accuracy require timely solutions. In this article, various avenues available for TinyML implementation are reviewed. Firstly, a background of TinyML is provided, followed by detailed discussions on various tools supporting TinyML. Then, state-of-art applications of TinyML using advanced technologies are detailed. Lastly, detailed prospects are presented which include various research challenges and identification of future directions.},
  day      = {01},
  doi      = {10.1007/s11042-023-16740-9},
  url      = {https://doi.org/10.1007/s11042-023-16740-9},
}

@mastersthesis{quantization,
  author       = {Claudio Moriello},
  title        = {Optimizing Neural Networks for TinyML: A Study on Quantization Schemes},
  school       = {Politecnico di Milano},
  year         = {2024},
  month        = {July},
  type         = {Master's Thesis},
  supervisor   = {Manuel Roveri},
  url          = {https://hdl.handle.net/10589/222539}
}

@Article{Rainio2024,
  author   = {Rainio, Oona and Teuho, Jarmo and Klén, Riku},
  journal  = {Scientific Reports},
  title    = {Evaluation metrics and statistical tests for machine learning},
  year     = {2024},
  issn     = {2045-2322},
  number   = {1},
  pages    = {6086},
  volume   = {14},
  abstract = {Research on different machine learning (ML) has become incredibly popular during the past few decades. However, for some researchers not familiar with statistics, it might be difficult to understand how to evaluate the performance of ML models and compare them with each other. Here, we introduce the most common evaluation metrics used for the typical supervised ML tasks including binary, multi-class, and multi-label classification, regression, image segmentation, object detection, and information retrieval. We explain how to choose a suitable statistical test for comparing models, how to obtain enough values of the metric for testing, and how to perform the test and interpret its results. We also present a few practical examples about comparing convolutional neural networks used to classify X-rays with different lung infections and detect cancer tumors in positron emission tomography images.},
  doi      = {10.1038/s41598-024-56706-x},
  refid    = {Rainio2024},
  url      = {https://doi.org/10.1038/s41598-024-56706-x},
}

@Article{Alshammari2024,
  author  = {Alshammari, Ahmad},
  journal = {International Journal of Computer Applications},
  title   = {Implementation of Model Evaluation using Confusion Matrix in Python},
  year    = {2024},
  month   = {11},
  pages   = {42-48},
  volume  = {186},
  doi     = {10.5120/ijca2024924236},
}

@Manual{edgeDocs,
  title  = {Image Classification - Edge Impulse Documentation},
  author = {{Edge Impulse}},
  note   = {Acessado em: 7 jun. 2025},
  year   = {2025},
  url    = {https://docs.edgeimpulse.com/docs/tutorials/end-to-end-tutorials/computer-vision/image-classification},
}

@Manual{tensorDocs,
  title  = {Image Classification - TensorFlow Models},
  author = {{TensorFlow}},
  note   = {Acessado em: 7 jun. 2025},
  year   = {2023},
  url    = {https://www.tensorflow.org/tfmodels/vision/image_classification},
}

@Article{Oliveira2024,
  author   = {Franklin Oliveira and Daniel G. Costa and Flávio Assis and Ivanovitch Silva},
  journal  = {Internet of Things},
  title    = {Internet of Intelligent Things: A convergence of embedded systems, edge computing and machine learning},
  year     = {2024},
  issn     = {2542-6605},
  pages    = {101153},
  volume   = {26},
  abstract = {This article comprehensively reviews the emerging concept of Internet of Intelligent Things (IoIT), adopting an integrated perspective centred on the areas of embedded systems, edge computing, and machine learning. With rapid developments in these areas, new solutions are emerging to address previously unsolved problems, demanding novel research and development paradigms. In this sense, this article aims to fulfil some important research gaps, laying down the foundations for cutting-edge research works following an ever-increasing trend based on embedded devices powered by compressed artificial intelligence models. For that, this article first traces the evolution of embedded devices and wireless communication technologies in the last decades, leading to the emergence of IoT applications in various domains. The evolution of machine learning and its applications, along with associated challenges and architectures, is also discussed. In this context, the concept of embedded machine learning (TinyML) is introduced within the context of the Internet of Intelligent Things paradigm, highlighting its unique characteristics and the process of developing and deploying such solutions. Furthermore, we perform an extensive state-of-the-art survey to identify very recent works that have implemented TinyML models on different off-the-shelf embedded devices, analysing the development of practical solutions and discussing recent research trends and future perspectives. By providing a comprehensive literature review across all layers of the Internet of Intelligent Things paradigm, addressing potential applications and proposing a new taxonomy to guide new development efforts, this article aims to offer a holistic perspective on this challenging and rapidly evolving research field.},
  doi      = {https://doi.org/10.1016/j.iot.2024.101153},
  keywords = {TinyML, IoT, Hardware, Artificial intelligence, Survey},
  url      = {https://www.sciencedirect.com/science/article/pii/S2542660524000945},
}

@Comment{jabref-meta: databaseType:bibtex;}
